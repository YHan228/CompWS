{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kintsugi Demo\n",
        "\n",
        "Generate kintsugi overlays for OOD perturbations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "from src.models.vae import KintsugiVAE, vae_loss\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "from src.viz.kintsugi import (\n",
        "    add_gaussian_noise,\n",
        "    add_occlusion,\n",
        "    create_kintsugi_grid,\n",
        "    mix_digits,\n",
        "    rotate_image,\n",
        ")\n",
        "\n",
        "SMOKE_TEST = True\n",
        "\n",
        "results_dir = Path('results')\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "checkpoint_path = results_dir / 'vae_mnist.pt'\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = KintsugiVAE(z_dim=20).to(device)\n",
        "\n",
        "if checkpoint_path.exists():\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "else:\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "    if SMOKE_TEST:\n",
        "        train_dataset = Subset(train_dataset, list(range(1000)))\n",
        "        epochs = 2\n",
        "    else:\n",
        "        epochs = 30\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch, _ in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            recon, mu, log_var = model(batch)\n",
        "            loss = vae_loss(recon, batch, mu, log_var)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
        "batch, _ = next(iter(test_loader))\n",
        "base_images = batch[:4]\n",
        "\n",
        "perturbations = {}\n",
        "perturbations['occlusion'] = torch.stack([add_occlusion(img) for img in base_images])\n",
        "perturbations['noise'] = torch.stack([add_gaussian_noise(img) for img in base_images])\n",
        "perturbations['rotation'] = torch.stack([rotate_image(img, angle=45) for img in base_images])\n",
        "mixed = []\n",
        "for i in range(4):\n",
        "    mixed.append(mix_digits(base_images[i], base_images[(i + 1) % 4]))\n",
        "perturbations['mix'] = torch.stack(mixed)\n",
        "\n",
        "rows = []\n",
        "for name, images in perturbations.items():\n",
        "    grid = create_kintsugi_grid(model, images, n_mc_samples=20, cols=4)\n",
        "    rows.append(grid)\n",
        "\n",
        "grid_width = rows[0].width\n",
        "grid_height = sum(row.height for row in rows)\n",
        "gallery = Image.new('RGB', (grid_width, grid_height))\n",
        "y_offset = 0\n",
        "for row in rows:\n",
        "    gallery.paste(row, (0, y_offset))\n",
        "    y_offset += row.height\n",
        "\n",
        "output_path = results_dir / 'kintsugi_gallery.png'\n",
        "gallery.save(output_path)\n",
        "print(f'Saved gallery to {output_path}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}